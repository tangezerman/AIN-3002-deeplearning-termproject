{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuE424KJDlbH"
      },
      "source": [
        "MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLko_68qOq9R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1LmZ4fxOq9T",
        "outputId": "9a32f45e-4534-4d34-9f7c-cd57cc680568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available() :\n",
        "    device = torch.device(\"mps\")\n",
        "else: \n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkI9iHsxOq9U"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec8eufhyOq9W",
        "outputId": "db6c139d-e0e9-4241-9f30-5b65a2c1f62e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x10ca7c3b0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 256 #16\n",
        "epochs = 10\n",
        "torch.manual_seed(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lo6v4OfOq9W"
      },
      "source": [
        "Initializing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSr4kPOZOq9X"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(root=\"datasets/\",train=True,transform=transforms.ToTensor(),download=True)\n",
        "train_loader = DataLoader(dataset = train_dataset,batch_size=batch_size,shuffle = True)\n",
        "test_dataset = datasets.MNIST(root=\"datasets/\",train=False,transform=transforms.ToTensor(),download=True)\n",
        "test_loader = DataLoader(dataset = test_dataset,batch_size=batch_size,shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm-Q5nnfOq9X"
      },
      "source": [
        "Network Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2JOOuGoDlbL"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0],-1)\n",
        "            \n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "    print(f'Got{num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVlE-eTPDlbL"
      },
      "source": [
        "Testing 3 different architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSqAGMAwOq9a",
        "outputId": "5059cb5e-c312-4d63-8e6a-fe75356fa601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got59801/60000 with accuracy 99.67\n",
            "Got9774/10000 with accuracy 97.74\n"
          ]
        }
      ],
      "source": [
        "#architecture 1\n",
        "class NN(nn.Module):\n",
        "    def __init__(self,input,classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input,256)\n",
        "        self.fc2 = nn.Linear(256,128)\n",
        "        self.fc3 = nn.Linear(128,num_classes)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "model = NN(input_size,classes = num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range (epochs):\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "        data = data.to(device=device)\n",
        "        target = target.to(device = device)\n",
        "        \n",
        "        data = data.reshape(data.shape[0],-1)\n",
        "        #forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, target)\n",
        "        #setting each gradient to 0 \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #gradient descent\n",
        "        optimizer.step()\n",
        "def check_accuracy(loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0],-1)\n",
        "            \n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "    print(f'Got{num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "    model.train()\n",
        "check_accuracy(train_loader,model)\n",
        "check_accuracy(test_loader,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r09n7r5LDlbM",
        "outputId": "2a04f81c-93ad-4c63-e116-6a276c990cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got59875/60000 with accuracy 99.79\n",
            "Got9795/10000 with accuracy 97.95\n"
          ]
        }
      ],
      "source": [
        "#architecture 2\n",
        "class NN(nn.Module):\n",
        "    def __init__(self,input,classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input,512)\n",
        "        self.fc2 = nn.Linear(512,256)\n",
        "        self.fc3 = nn.Linear(256,num_classes)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "model = NN(input_size,classes = num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range (epochs):\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "        data = data.to(device=device)\n",
        "        target = target.to(device = device)\n",
        "        \n",
        "        data = data.reshape(data.shape[0],-1)\n",
        "        #forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, target)\n",
        "        #setting each gradient to 0 \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #gradient descent\n",
        "        optimizer.step()\n",
        "def check_accuracy(loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0],-1)\n",
        "            \n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "    print(f'Got{num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "    model.train()\n",
        "check_accuracy(train_loader,model)\n",
        "check_accuracy(test_loader,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nMbjeXjDlbN",
        "outputId": "f3894ce5-c467-42fe-d345-6f9d091c9597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got59406/60000 with accuracy 99.01\n",
            "Got9762/10000 with accuracy 97.62\n"
          ]
        }
      ],
      "source": [
        "#architecture 3\n",
        "class NN(nn.Module):\n",
        "    def __init__(self,input,classes):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input,128)\n",
        "        self.fc2 = nn.Linear(128,64)\n",
        "        self.fc3 = nn.Linear(64,num_classes)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "model = NN(input_size,classes = num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range (epochs):\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "        data = data.to(device=device)\n",
        "        target = target.to(device = device)\n",
        "        \n",
        "        data = data.reshape(data.shape[0],-1)\n",
        "        #forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, target)\n",
        "        #setting each gradient to 0 \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #gradient descent\n",
        "        optimizer.step()\n",
        "def check_accuracy(loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0],-1)\n",
        "            \n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "    print(f'Got{num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "    model.train()\n",
        "check_accuracy(train_loader,model)\n",
        "check_accuracy(test_loader,model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSB1I-v6DlbN"
      },
      "source": [
        "Selecting the best architecture to apply dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzcJNv8kDlbN",
        "outputId": "f5e06d6b-5b20-4f3d-f811-e057726b5565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with dropout rate: 0.2\n",
            "Training set:\n",
            "Got59828/60000 with accuracy 99.71\n",
            "Test set:\n",
            "Got9816/10000 with accuracy 98.16\n",
            "\n",
            "Training with dropout rate: 0.3\n",
            "Training set:\n",
            "Got59783/60000 with accuracy 99.64\n",
            "Test set:\n",
            "Got9823/10000 with accuracy 98.23\n",
            "\n",
            "Training with dropout rate: 0.4\n",
            "Training set:\n",
            "Got59734/60000 with accuracy 99.56\n",
            "Test set:\n",
            "Got9835/10000 with accuracy 98.35\n",
            "\n",
            "Training with dropout rate: 0.5\n",
            "Training set:\n",
            "Got59577/60000 with accuracy 99.30\n",
            "Test set:\n",
            "Got9799/10000 with accuracy 97.99\n",
            "\n",
            "Training with dropout rate: 0.6\n",
            "Training set:\n",
            "Got59387/60000 with accuracy 98.98\n",
            "Test set:\n",
            "Got9789/10000 with accuracy 97.89\n",
            "\n",
            "Training with dropout rate: 0.7\n",
            "Training set:\n",
            "Got59071/60000 with accuracy 98.45\n",
            "Test set:\n",
            "Got9783/10000 with accuracy 97.83\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#architecture 2 with dropout\n",
        "dropout_rates = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]  # List of dropout rates to try\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, dropout_rate):\n",
        "        super(NN, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "for dropout_rate in dropout_rates:\n",
        "    print(f\"Training with dropout rate: {dropout_rate}\")\n",
        "    model = NN(input_size, num_classes, dropout_rate).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.to(device=device)\n",
        "            target = target.to(device=device)\n",
        "            data = data.reshape(data.shape[0], -1)\n",
        "            \n",
        "            # Forward pass\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, target)\n",
        "            \n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate on training and test sets\n",
        "    print(\"Training set:\")\n",
        "    check_accuracy(train_loader, model)\n",
        "    print(\"Test set:\")\n",
        "    check_accuracy(test_loader, model)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jinC2KEaUPA5"
      },
      "source": [
        "Cifar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Dz9gk287PG"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(20)\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5BGGzG9UQQA"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLJGsSs1ajRA",
        "outputId": "becb8210-e591-49e5-b84a-a207d660898c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.CIFAR10(root=\"datasets/\", train = True, download = True, transform = transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = datasets.CIFAR10(root=\"datasets/\",train=False, download = True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UeC8eleDlbO"
      },
      "source": [
        "Testing 3 different architectures and adding momentum do SGD to the best perforing network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmxW78yxDlbO",
        "outputId": "aab2eb89-af19-4ffc-f7d5-1419b1675d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 44.41 %\n",
            "Accuracy of plane: 47.4 %\n",
            "Accuracy of car: 56.8 %\n",
            "Accuracy of bird: 32.5 %\n",
            "Accuracy of cat: 24.8 %\n",
            "Accuracy of deer: 32.4 %\n",
            "Accuracy of dog: 34.8 %\n",
            "Accuracy of frog: 59.0 %\n",
            "Accuracy of horse: 54.1 %\n",
            "Accuracy of ship: 51.6 %\n",
            "Accuracy of truck: 50.7 %\n"
          ]
        }
      ],
      "source": [
        "#architecture 1     \n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))  \n",
        "        x = self.pool(F.relu(self.conv2(x)))  \n",
        "        x = x.view(-1, 16 * 5 * 5)            \n",
        "        x = F.relu(self.fc1(x))               \n",
        "        x = F.relu(self.fc2(x))              \n",
        "        x = self.fc3(x)                       \n",
        "        return x\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (images,labels) in enumerate (train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_samples = [0 for _ in range(10)]\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            \n",
        "            n_class_samples[label] += 1\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4zx8tdIDlbO",
        "outputId": "9a141369-e695-4c34-eac2-519abcc236bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 45.64 %\n",
            "Accuracy of plane: 51.9 %\n",
            "Accuracy of car: 65.9 %\n",
            "Accuracy of bird: 29.1 %\n",
            "Accuracy of cat: 27.7 %\n",
            "Accuracy of deer: 28.7 %\n",
            "Accuracy of dog: 34.2 %\n",
            "Accuracy of frog: 58.5 %\n",
            "Accuracy of horse: 52.5 %\n",
            "Accuracy of ship: 55.5 %\n",
            "Accuracy of truck: 52.4 %\n"
          ]
        }
      ],
      "source": [
        "#architecture 2 \n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))  \n",
        "        x = self.pool(F.relu(self.conv2(x)))  \n",
        "        x = x.view(-1, 16 * 5 * 5)            \n",
        "        x = F.relu(self.fc1(x))               \n",
        "        x = F.relu(self.fc2(x))               \n",
        "        x = self.fc3(x)                       \n",
        "        return x\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (images,labels) in enumerate (train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_samples = [0 for _ in range(10)]\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            \n",
        "            n_class_samples[label] += 1\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axtvGPRoDlbO",
        "outputId": "719de4c5-32b4-49ff-b2fd-d81de88ebcc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 47.42 %\n",
            "Accuracy of plane: 46.4 %\n",
            "Accuracy of car: 48.5 %\n",
            "Accuracy of bird: 22.4 %\n",
            "Accuracy of cat: 22.5 %\n",
            "Accuracy of deer: 31.2 %\n",
            "Accuracy of dog: 51.3 %\n",
            "Accuracy of frog: 72.2 %\n",
            "Accuracy of horse: 55.0 %\n",
            "Accuracy of ship: 58.5 %\n",
            "Accuracy of truck: 66.2 %\n"
          ]
        }
      ],
      "source": [
        "#architecture 3 \n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))  \n",
        "        x = self.pool(F.relu(self.conv2(x)))  \n",
        "        x = x.view(-1, 16 * 5 * 5)            \n",
        "        x = F.relu(self.fc1(x))               \n",
        "        x = F.relu(self.fc2(x))               \n",
        "        x = self.fc3(x)                       \n",
        "        return x\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (images,labels) in enumerate (train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_samples = [0 for _ in range(10)]\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            \n",
        "            n_class_samples[label] += 1\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2W6dukFDlbP",
        "outputId": "e4622181-2e48-4e00-8373-bd15f38d6d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 63.48 %\n",
            "Accuracy of plane: 77.7 %\n",
            "Accuracy of car: 78.3 %\n",
            "Accuracy of bird: 49.9 %\n",
            "Accuracy of cat: 42.5 %\n",
            "Accuracy of deer: 54.9 %\n",
            "Accuracy of dog: 42.5 %\n",
            "Accuracy of frog: 80.7 %\n",
            "Accuracy of horse: 66.3 %\n",
            "Accuracy of ship: 75.1 %\n",
            "Accuracy of truck: 66.9 %\n"
          ]
        }
      ],
      "source": [
        "#architecture 3 with momentum\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))  \n",
        "        x = self.pool(F.relu(self.conv2(x)))  \n",
        "        x = x.view(-1, 16 * 5 * 5)            \n",
        "        x = F.relu(self.fc1(x))               \n",
        "        x = F.relu(self.fc2(x))               \n",
        "        x = self.fc3(x)                       \n",
        "        return x\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "total_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (images,labels) in enumerate (train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_samples = [0 for _ in range(10)]\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            \n",
        "            n_class_samples[label] += 1\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-MZngknDlbP"
      },
      "source": [
        "Testing different dropout rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQSXhzZVDlbP",
        "outputId": "a292dc67-1c26-4a2b-9bc4-91665ff78edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network with dropout rate 0.2: 64.43 %\n",
            "Accuracy of plane with dropout rate 0.2: 72.7 %\n",
            "Accuracy of car with dropout rate 0.2: 74.5 %\n",
            "Accuracy of bird with dropout rate 0.2: 60.3 %\n",
            "Accuracy of cat with dropout rate 0.2: 47.9 %\n",
            "Accuracy of deer with dropout rate 0.2: 56.0 %\n",
            "Accuracy of dog with dropout rate 0.2: 47.1 %\n",
            "Accuracy of frog with dropout rate 0.2: 78.8 %\n",
            "Accuracy of horse with dropout rate 0.2: 65.4 %\n",
            "Accuracy of ship with dropout rate 0.2: 74.5 %\n",
            "Accuracy of truck with dropout rate 0.2: 67.1 %\n",
            "Accuracy of the network with dropout rate 0.3: 65.5 %\n",
            "Accuracy of plane with dropout rate 0.3: 71.2 %\n",
            "Accuracy of car with dropout rate 0.3: 75.9 %\n",
            "Accuracy of bird with dropout rate 0.3: 51.2 %\n",
            "Accuracy of cat with dropout rate 0.3: 48.6 %\n",
            "Accuracy of deer with dropout rate 0.3: 63.2 %\n",
            "Accuracy of dog with dropout rate 0.3: 40.6 %\n",
            "Accuracy of frog with dropout rate 0.3: 76.7 %\n",
            "Accuracy of horse with dropout rate 0.3: 71.9 %\n",
            "Accuracy of ship with dropout rate 0.3: 83.6 %\n",
            "Accuracy of truck with dropout rate 0.3: 72.1 %\n",
            "Accuracy of the network with dropout rate 0.4: 63.63 %\n",
            "Accuracy of plane with dropout rate 0.4: 73.1 %\n",
            "Accuracy of car with dropout rate 0.4: 72.9 %\n",
            "Accuracy of bird with dropout rate 0.4: 58.2 %\n",
            "Accuracy of cat with dropout rate 0.4: 37.8 %\n",
            "Accuracy of deer with dropout rate 0.4: 52.8 %\n",
            "Accuracy of dog with dropout rate 0.4: 55.5 %\n",
            "Accuracy of frog with dropout rate 0.4: 74.2 %\n",
            "Accuracy of horse with dropout rate 0.4: 71.1 %\n",
            "Accuracy of ship with dropout rate 0.4: 75.5 %\n",
            "Accuracy of truck with dropout rate 0.4: 65.2 %\n",
            "Accuracy of the network with dropout rate 0.5: 63.82 %\n",
            "Accuracy of plane with dropout rate 0.5: 74.0 %\n",
            "Accuracy of car with dropout rate 0.5: 77.5 %\n",
            "Accuracy of bird with dropout rate 0.5: 52.3 %\n",
            "Accuracy of cat with dropout rate 0.5: 35.0 %\n",
            "Accuracy of deer with dropout rate 0.5: 57.0 %\n",
            "Accuracy of dog with dropout rate 0.5: 59.9 %\n",
            "Accuracy of frog with dropout rate 0.5: 74.4 %\n",
            "Accuracy of horse with dropout rate 0.5: 69.2 %\n",
            "Accuracy of ship with dropout rate 0.5: 71.9 %\n",
            "Accuracy of truck with dropout rate 0.5: 67.0 %\n",
            "Accuracy of the network with dropout rate 0.6: 64.07 %\n",
            "Accuracy of plane with dropout rate 0.6: 74.9 %\n",
            "Accuracy of car with dropout rate 0.6: 78.0 %\n",
            "Accuracy of bird with dropout rate 0.6: 58.5 %\n",
            "Accuracy of cat with dropout rate 0.6: 45.0 %\n",
            "Accuracy of deer with dropout rate 0.6: 56.4 %\n",
            "Accuracy of dog with dropout rate 0.6: 45.0 %\n",
            "Accuracy of frog with dropout rate 0.6: 77.1 %\n",
            "Accuracy of horse with dropout rate 0.6: 62.6 %\n",
            "Accuracy of ship with dropout rate 0.6: 77.0 %\n",
            "Accuracy of truck with dropout rate 0.6: 66.2 %\n",
            "Accuracy of the network with dropout rate 0.7: 62.41 %\n",
            "Accuracy of plane with dropout rate 0.7: 62.5 %\n",
            "Accuracy of car with dropout rate 0.7: 80.0 %\n",
            "Accuracy of bird with dropout rate 0.7: 49.7 %\n",
            "Accuracy of cat with dropout rate 0.7: 31.7 %\n",
            "Accuracy of deer with dropout rate 0.7: 53.2 %\n",
            "Accuracy of dog with dropout rate 0.7: 61.4 %\n",
            "Accuracy of frog with dropout rate 0.7: 81.3 %\n",
            "Accuracy of horse with dropout rate 0.7: 58.9 %\n",
            "Accuracy of ship with dropout rate 0.7: 78.2 %\n",
            "Accuracy of truck with dropout rate 0.7: 67.2 %\n"
          ]
        }
      ],
      "source": [
        "dropout_rates = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)  \n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        " \n",
        "\n",
        "for dropout_rate in dropout_rates:\n",
        "    model = ConvNet().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    model.dropout.p = dropout_rate  \n",
        "\n",
        "    total_steps = len(train_loader)\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        n_class_correct = [0 for _ in range(10)]\n",
        "        n_class_samples = [0 for _ in range(10)]\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            for i in range(labels.size(0)):\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "\n",
        "                n_class_samples[label] += 1\n",
        "                if label == pred:\n",
        "                    n_class_correct[label] += 1\n",
        "\n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(f'Accuracy of the network with dropout rate {dropout_rate}: {acc} %')\n",
        "\n",
        "        for i in range(10):\n",
        "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "            print(f'Accuracy of {classes[i]} with dropout rate {dropout_rate}: {acc} %')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giCKNgXGDlbP"
      },
      "source": [
        "Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml78hS4Yqtqm"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(42)\n",
        "# Define batch size for training\n",
        "batch_size = 256\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Transform the data to tensors and normalize it\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5,))])\n",
        "\n",
        "# Download and load the FashionMNIST dataset\n",
        "trainset = torchvision.datasets.FashionMNIST(root='datasets/', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='datasets/', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the classes in the FashionMNIST dataset\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress',\n",
        "           'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmOk9tp1DlbP",
        "outputId": "168f2cb4-ea00-4164-d6c1-465110bfd85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of T-shirt/top: 81.70%\n",
            "Accuracy of Trouser: 88.70%\n",
            "Accuracy of Pullover: 4.10%\n",
            "Accuracy of Dress: 13.40%\n",
            "Accuracy of Coat: 66.10%\n",
            "Accuracy of Sandal: 75.90%\n",
            "Accuracy of Shirt: 5.00%\n",
            "Accuracy of Sneaker: 81.20%\n",
            "Accuracy of Bag: 4.80%\n",
            "Accuracy of Ankle boot: 82.30%\n",
            "Overall accuracy on the 10000 test images: 50.32%\n"
          ]
        }
      ],
      "source": [
        "#architecture 1\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += (predicted[i] == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    accuracy = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'Accuracy of {classes[i]}: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "overall_accuracy = 100 * correct / total\n",
        "print(f'Overall accuracy on the {len(testset)} test images: {overall_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cglYST6UDlbQ",
        "outputId": "87d25d9c-5df3-4cbf-eaea-389d6834a3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of T-shirt/top: 10.90%\n",
            "Accuracy of Trouser: 86.40%\n",
            "Accuracy of Pullover: 34.40%\n",
            "Accuracy of Dress: 55.40%\n",
            "Accuracy of Coat: 88.00%\n",
            "Accuracy of Sandal: 25.80%\n",
            "Accuracy of Shirt: 0.40%\n",
            "Accuracy of Sneaker: 84.10%\n",
            "Accuracy of Bag: 74.80%\n",
            "Accuracy of Ankle boot: 94.70%\n",
            "Overall accuracy on the 10000 test images: 55.49%\n"
          ]
        }
      ],
      "source": [
        "#architecture 2\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # Get the inputs and labels\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += (predicted[i] == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    accuracy = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'Accuracy of {classes[i]}: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "overall_accuracy = 100 * correct / total\n",
        "print(f'Overall accuracy on the {len(testset)} test images: {overall_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yymq8MboDlbQ",
        "outputId": "e72a3290-d44a-40b7-e59f-a5efdfdf78ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of T-shirt/top: 64.00%\n",
            "Accuracy of Trouser: 92.00%\n",
            "Accuracy of Pullover: 22.50%\n",
            "Accuracy of Dress: 55.20%\n",
            "Accuracy of Coat: 71.70%\n",
            "Accuracy of Sandal: 79.90%\n",
            "Accuracy of Shirt: 7.30%\n",
            "Accuracy of Sneaker: 78.10%\n",
            "Accuracy of Bag: 78.10%\n",
            "Accuracy of Ankle boot: 92.70%\n",
            "Overall accuracy on the 10000 test images: 64.15%\n"
          ]
        }
      ],
      "source": [
        "#architecture 3\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += (predicted[i] == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    accuracy = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'Accuracy of {classes[i]}: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "overall_accuracy = 100 * correct / total\n",
        "print(f'Overall accuracy on the {len(testset)} test images: {overall_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1L5ZPFTDlbQ",
        "outputId": "583619d5-6d27-499e-f696-a5f3e3e1b177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of T-shirt/top: 82.10%\n",
            "Accuracy of Trouser: 94.60%\n",
            "Accuracy of Pullover: 71.50%\n",
            "Accuracy of Dress: 84.90%\n",
            "Accuracy of Coat: 85.30%\n",
            "Accuracy of Sandal: 91.50%\n",
            "Accuracy of Shirt: 37.80%\n",
            "Accuracy of Sneaker: 95.00%\n",
            "Accuracy of Bag: 94.80%\n",
            "Accuracy of Ankle boot: 92.10%\n",
            "Overall accuracy on the 10000 test images: 82.96%\n"
          ]
        }
      ],
      "source": [
        "#architecture 3 with momentum\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate,momentum=0.9)\n",
        "\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += (predicted[i] == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    accuracy = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'Accuracy of {classes[i]}: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "overall_accuracy = 100 * correct / total\n",
        "print(f'Overall accuracy on the {len(testset)} test images: {overall_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Uoi9SCqDlbQ",
        "outputId": "30ad05fb-4edc-46e8-83f1-1b1ca06b0a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with dropout rate: 0.2\n",
            "Accuracy with dropout rate 0.2: 81.50%\n",
            "Training with dropout rate: 0.3\n",
            "Accuracy with dropout rate 0.3: 85.92%\n",
            "Training with dropout rate: 0.4\n",
            "Accuracy with dropout rate 0.4: 87.61%\n",
            "Training with dropout rate: 0.5\n",
            "Accuracy with dropout rate 0.5: 87.96%\n",
            "Training with dropout rate: 0.6\n",
            "Accuracy with dropout rate 0.6: 88.97%\n",
            "Training with dropout rate: 0.7\n",
            "Accuracy with dropout rate 0.7: 89.10%\n"
          ]
        }
      ],
      "source": [
        "#architecture 3 with momentum and dropout \n",
        "dropout_rates = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout_rate):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = CNN(dropout_rates[0]).to(device)\n",
        "\n",
        "for dropout_rate in dropout_rates:\n",
        "    print(f\"Training with dropout rate: {dropout_rate}\")\n",
        "    \n",
        "\n",
        "    net.dropout.p = dropout_rate\n",
        "    \n",
        "  \n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            \n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    \n",
        "    accuracy = 100 * correct / total\n",
        "    \n",
        "    print(f'Accuracy with dropout rate {dropout_rate}: {accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tensyflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}